{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import math\n",
    "from enum import Enum\n",
    "from torch.utils.data import TensorDataset, DataLoader, ConcatDataset\n",
    "from sklearn.model_selection import KFold\n",
    "import math\n",
    "import pickle\n",
    "import datetime\n",
    "import os \n",
    "from sklearn.model_selection import KFold\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
    "os.environ[\"TORCH_USE_CUDA_DSA\"] = \"1\"\n",
    "BATCH_SIZE = 64\n",
    "CNN_KERNAL_SIZE = 3\n",
    "#TODO: build a validation/test split\n",
    "k_folds = 5\n",
    "num_epochs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check if GPU is available and select if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "print(torch.cuda.is_available())\n",
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing user data\n",
    "\n",
    "subjects = []\n",
    "for i in range (1,31):\n",
    "    interimPysch = pd.read_csv('.\\\\CASE_full\\\\data\\\\non-interpolated\\\\physiological\\\\sub_' + str(i) + '.csv')\n",
    "    interimPysch = interimPysch.drop(columns=['video'])\n",
    "    interimPysch['daqtime'] = interimPysch['daqtime'].astype('int32')\n",
    "    interimAnote = pd.read_csv('.\\\\CASE_full\\\\data\\\\non-interpolated\\\\annotations\\\\sub_' + str(i) + '.csv')\n",
    "    interimAnote = interimAnote.drop(columns=['video'])\n",
    "    interimAnote['jstime'] = interimAnote['jstime'].astype('int32')\n",
    "    final = interimPysch.merge(interimAnote, left_on='daqtime',right_on='jstime', how='outer')\n",
    "    #jstime dropped as it is redundant\n",
    "    final = final.drop(columns=['jstime','daqtime'])\n",
    "    final = final.ffill()\n",
    "    final = final.bfill()\n",
    "    final.to_csv('.\\\\Processed-Data\\\\KfoldProcess\\\\sub_' + str(i) + '_processed'+'.csv')\n",
    "    subjects.append(final)\n",
    "subjects[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def createStressLevel(Dataframe):\n",
    "    vals = []\n",
    "    valence = Dataframe.loc[:,'valence']\n",
    "    arousal = Dataframe.loc[:,'arousal']\n",
    "    for i in range(0,len(valence)):\n",
    "        vals.append(round((arousal[i]-0.5)*math.cos((math.pi/18)*(valence[i] - 0.5))))\n",
    "    return vals\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for KFOLD we load everything into one dataset and then split later down the road.\n",
    "subjects = []\n",
    "\n",
    "for i in range(1,31):\n",
    "      temp = pd.read_csv('.\\\\Processed-Data\\\\Filled-Data\\\\sub_' + str(i) + '_processed'+'.csv')\n",
    "      temp['StressLevel'] = createStressLevel(temp)\n",
    "      subjects.append(temp)\n",
    "\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "subjects[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combining Dataset and train set frames\n",
    "#it may be required that timestamps be dropped from the prediciton model entirely, or atleast switched to date time, as the model\n",
    "#may try to learn emotions based on when measuring starts and finishes. This could be problematic\n",
    "#as sessions in the field could go longer than eny training sessions, or disconnects could restart sessions\n",
    "datasetFrame = pd.concat(subjects.copy())\n",
    "datasetFrame = datasetFrame.drop(columns=['Unnamed: 0'])\n",
    "Labels = torch.Tensor(datasetFrame['StressLevel'].values.astype(int))\n",
    "datasetFrame = datasetFrame.drop(columns=['StressLevel','valence','arousal'])\n",
    "\n",
    "datasetFrame.to_csv('.\\\\Processed-Data\\\\KFOLD-FULL\\\\trainingData.csv',index=False)\n",
    "pickle.dump(Labels, open('.\\\\Processed-Data\\\\KFOLD-FULL\\\\Labels.pkl','wb'))\n",
    "\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Labels = pickle.load(open('.\\\\Processed-Data\\\\KFOLD-FULL\\\\Labels.pkl','rb')).to(device)\n",
    "\n",
    "datasetFrame = pd.read_csv('.\\\\Processed-Data\\\\KFOLD-FULL\\\\trainingData.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainTensor = torch.tensor(datasetFrame.values.astype(float),dtype=torch.float32).to(device)\n",
    "print(f\"Shape: {trainTensor.shape} Type: {trainTensor.dtype}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_Set = TensorDataset(trainTensor,Labels)\n",
    "print(f'Data_Set Length: {len(Data_Set)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_weights(model):\n",
    "  \"\"\"performed to avoid weight leakage\"\"\"\n",
    "  for layer in model.children():\n",
    "    if hasattr(layer, 'reset_parameters'):\n",
    "      layer.reset_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#definining the model\n",
    "#proposed function for stress level S = A/V where S is stress, A is arousal, and V is valence\n",
    "#since valence represents the positivity of the emotion, it would be inversely proportional to stress as higher valence means a better emotion\n",
    "#Since higher arousal can be generally translated to \n",
    "class StressScanner(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(StressScanner, self).__init__()\n",
    "        self.ConvolutionIn = torch.nn.Conv1d(in_channels=8, out_channels=16,kernel_size=CNN_KERNAL_SIZE,padding=1)\n",
    "        self.ConvHidden1 = torch.nn.Conv1d(in_channels=16, out_channels=32,kernel_size=CNN_KERNAL_SIZE,padding=1)\n",
    "        self.ConvHidden2 = torch.nn.Conv1d(in_channels=32, out_channels=32,kernel_size=CNN_KERNAL_SIZE,padding=1)\n",
    "        self.ConvHidden3 = torch.nn.Conv1d(in_channels=32, out_channels=20,kernel_size=CNN_KERNAL_SIZE,padding=1)\n",
    "        self.ConvOUT = torch.nn.Conv1d(in_channels=20, out_channels=10,kernel_size=CNN_KERNAL_SIZE,padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.ConvolutionIn(x))\n",
    "        x = F.relu(self.ConvHidden1(x))\n",
    "        x = F.relu(self.ConvHidden2(x))\n",
    "        x = F.relu(self.ConvHidden3(x))\n",
    "        x = self.ConvOUT(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.CrossEntropyLoss().to(device)\n",
    "kfold = KFold(n_splits=k_folds, shuffle=True)\n",
    "results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train loop\n",
    "#Note: tb_writer is just a tensorboard writer for statistics\n",
    "def train():\n",
    "    current_loss = 0.0\n",
    "    last_loss = 0.0\n",
    "    for fold , (train_id, test_id) in enumerate(kfold.split(Data_Set)):\n",
    "        print(\"FOLD: \", fold)\n",
    "\n",
    "        train_subsampler = torch.utils.data.SubsetRandomSampler(train_id)\n",
    "        test_subsampler = torch.utils.data.SubsetRandomSampler(test_id)\n",
    "        #Preparing training and testing data using subsampling\n",
    "        Train_Loader = DataLoader(Data_Set,batch_size=BATCH_SIZE,sampler=train_subsampler)\n",
    "        Test_Loader = DataLoader(Data_Set,batch_size=BATCH_SIZE,sampler=test_subsampler)\n",
    "        \n",
    "        #initializing the model\n",
    "        model = StressScanner()\n",
    "        model.apply(reset_weights)\n",
    "        model = model.to(device)\n",
    "        #initialize optimizer\n",
    "        optimizer = torch.optim.ASGD(model.parameters(), lr=0.0001)\n",
    "        \n",
    "        #training function\n",
    "        for epoch in range (0,num_epochs):\n",
    "            print(f'Epoch: {epoch}')\n",
    "            current_loss = 0.0\n",
    "            \n",
    "            for i, batch in enumerate(Train_Loader, 0):\n",
    "                input, labels = batch\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                input = input.unsqueeze(2)\n",
    "                output = model(input)\n",
    "                \n",
    "                labels = labels.long()\n",
    "                labels = labels.unsqueeze(1)\n",
    "                loss = loss_fn(output,labels)\n",
    "                loss.backward()\n",
    "                \n",
    "                optimizer.step()\n",
    "                \n",
    "                current_loss += loss.item() \n",
    "                if (i % 1000 == 0):\n",
    "                    print(f'Epoch: {epoch} Loss: {current_loss}')\n",
    "                    last_loss = current_loss\n",
    "                    current_loss = 0.0\n",
    "            print(\"A model has been trained. Saving it now...\")\n",
    "            torch.save(model.state_dict(), f\"model_{fold}.pth\")\n",
    "            print(\"Testing model now...\")\n",
    "        with torch.no_grad():\n",
    "            total = 0\n",
    "            correct = 0\n",
    "            for i, batch in enumerate(Test_Loader, 0):\n",
    "                \n",
    "\n",
    "                input, labels = batch\n",
    "                input = input.unsqueeze(2)\n",
    "                output = model(input)\n",
    "                output = output.unsqueeze(2)\n",
    "\n",
    "                #get predicted values from the model\n",
    "                _, predicted = torch.max(output.data,1)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "                total += labels.size(0)\n",
    "                results[fold] = (correct/total)*100\n",
    "                print(f\"{fold} Fold Accuracy: {results[fold]}\")\n",
    "        print(\"CROSS VALIDATION COMPLETE\")\n",
    "        print(f\"TOTAL FOLDS: {k_folds}\")\n",
    "        print(f\"AVERAGE ACCURACY: {sum(results.values())/total}\")\n",
    "    return last_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Stress_Predictor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
