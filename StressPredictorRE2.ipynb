{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "from enum import Enum\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import math\n",
    "import pickle\n",
    "import datetime\n",
    "import os \n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
    "os.environ[\"TORCH_USE_CUDA_DSA\"] = \"1\"\n",
    "BATCH_SIZE = 1024\n",
    "#TODO: build a validation/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check if GPU is available and select if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "print(torch.cuda.is_available())\n",
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing user data\n",
    "\n",
    "subjects = []\n",
    "for i in range (1,31):\n",
    "    interimPysch = pd.read_csv('.\\\\CASE_full\\\\data\\\\non-interpolated\\\\physiological\\\\sub_' + str(i) + '.csv')\n",
    "    interimPysch = interimPysch.drop(columns=['video'])\n",
    "    interimPysch['daqtime'] = interimPysch['daqtime'].astype('int32')\n",
    "    interimAnote = pd.read_csv('.\\\\CASE_full\\\\data\\\\non-interpolated\\\\annotations\\\\sub_' + str(i) + '.csv')\n",
    "    interimAnote = interimAnote.drop(columns=['video'])\n",
    "    interimAnote['jstime'] = interimAnote['jstime'].astype('int32')\n",
    "    final = interimPysch.merge(interimAnote, left_on='daqtime',right_on='jstime', how='outer')\n",
    "    #jstime dropped as it is redundant\n",
    "    final = final.drop(columns=['jstime','daqtime'])\n",
    "    final = final.ffill()\n",
    "    final = final.bfill()\n",
    "    final.to_csv('.\\\\Processed-Data\\\\Filled-Data\\\\sub_' + str(i) + '_processed'+'.csv')\n",
    "    subjects.append(final)\n",
    "subjects[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def createStressLevel(Dataframe):\n",
    "    vals = []\n",
    "    valence = Dataframe.loc[:,'valence']\n",
    "    arousal = Dataframe.loc[:,'arousal']\n",
    "    for i in range(0,len(valence)):\n",
    "        vals.append((arousal[i]-0.5)*math.cos((math.pi/18)*(valence[i] - 0.5)))\n",
    "    return vals\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading datasets and converting them into tensors\n",
    "subjects = []\n",
    "global testSubjects\n",
    "global validationSubjects\n",
    "\n",
    "for i in range(1,31):\n",
    "   if i < 29:\n",
    "      temp = pd.read_csv('.\\\\Processed-Data\\\\Filled-Data\\\\sub_' + str(i) + '_processed'+'.csv')\n",
    "      temp['StressLevel'] = createStressLevel(temp)\n",
    "      subjects.append(temp)\n",
    "   elif i==29:\n",
    "      temp = pd.read_csv('.\\\\Processed-Data\\\\Filled-Data\\\\sub_' + str(i) + '_processed'+'.csv')\n",
    "      temp['StressLevel'] = createStressLevel(temp)\n",
    "      testSubjects = temp\n",
    "\n",
    "   else:\n",
    "      \n",
    "      temp = pd.read_csv('.\\\\Processed-Data\\\\Filled-Data\\\\sub_' + str(i) + '_processed'+'.csv')\n",
    "      temp['StressLevel'] = createStressLevel(temp)\n",
    "      validationSubjects = temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combining Dataset and train set frames\n",
    "#it may be required that timestamps be dropped from the prediciton model entirely, or atleast switched to date time, as the model\n",
    "#may try to learn emotions based on when measuring starts and finishes. This could be problematic\n",
    "#as sessions in the field could go longer than eny training sessions, or disconnects could restart sessions\n",
    "datasetFrame = pd.concat(subjects.copy())\n",
    "datasetFrame = datasetFrame.drop(columns=['Unnamed: 0'])\n",
    "trainLabels = torch.Tensor(datasetFrame['StressLevel'].values)\n",
    "datasetFrame = datasetFrame.drop(columns=['StressLevel','valence','arousal'])\n",
    "\n",
    "testFrame = testSubjects.copy()\n",
    "testFrame = testFrame.drop(columns=['Unnamed: 0']) \n",
    "testLabels = torch.Tensor(testFrame['StressLevel'].values) \n",
    "testFrame = testFrame.drop(columns=['StressLevel','valence','arousal'])\n",
    "\n",
    "validationFrame = validationSubjects.copy()\n",
    "validationFrame = validationFrame.drop(columns=['Unnamed: 0'])\n",
    "validationLabels = torch.Tensor(validationFrame['StressLevel'].values)\n",
    "validationFrame = validationFrame.drop(columns=['StressLevel','valence','arousal'])\n",
    "\n",
    "datasetFrame.to_csv('.\\\\Processed-Data\\\\STRESSPRED2\\\\trainingData.csv',index=False)\n",
    "testFrame.to_csv('.\\\\Processed-Data\\\\STRESSPRED2\\\\testData.csv',index=False)\n",
    "validationFrame.to_csv('.\\\\Processed-Data\\\\STRESSPRED2\\\\validationData.csv',index=False)\n",
    "pickle.dump(trainLabels, open('.\\\\Processed-Data\\\\STRESSPRED2\\\\trainLabels.pkl','wb'))\n",
    "pickle.dump(testLabels, open('.\\\\Processed-Data\\\\STRESSPRED2\\\\testLabels.pkl','wb'))\n",
    "pickle.dump(validationLabels, open('.\\\\Processed-Data\\\\STRESSPRED2\\\\validationLabels.pkl','wb'))\n",
    "\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainLabels = pickle.load(open('.\\\\Processed-Data\\\\STRESSPRED2\\\\trainLabels.pkl','rb')).to(device)\n",
    "testLabels = pickle.load(open('.\\\\Processed-Data\\\\STRESSPRED2\\\\testLabels.pkl','rb')).to(device)\n",
    "validationLabels = pickle.load(open('.\\\\Processed-Data\\\\STRESSPRED2\\\\validationLabels.pkl','rb')).to(device)\n",
    "datasetFrame = pd.read_csv('.\\\\Processed-Data\\\\STRESSPRED2\\\\trainingData.csv')\n",
    "testFrame = pd.read_csv('.\\\\Processed-Data\\\\STRESSPRED2\\\\testData.csv')\n",
    "validationFrame = pd.read_csv('.\\\\Processed-Data\\\\STRESSPRED2\\\\validationData.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainLabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainTensor = torch.tensor(datasetFrame.values.astype(float),dtype=torch.float32).to(device)\n",
    "testTensor = torch.tensor(testFrame.values.astype(float), dtype=torch.float32).to(device)\n",
    "validationTensor = torch.tensor(validationFrame.values.astype(float), dtype=torch.float32).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'trainTensor shape: {trainTensor.shape} testTensor shape: {testTensor.shape} validationTensor shape: {validationTensor.shape}' )\n",
    "print(f'Train type: {trainTensor.dtype} Test type: {testTensor.dtype} Validation type: {validationTensor.dtype}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainSet = TensorDataset(trainTensor,trainLabels)\n",
    "ValidationSet = TensorDataset(validationTensor,validationLabels)\n",
    "TestSet = TensorDataset(testTensor,testLabels)\n",
    "TrainLoader = DataLoader(TrainSet,BATCH_SIZE,shuffle=False)\n",
    "TestLoader = DataLoader(TestSet,BATCH_SIZE)\n",
    "ValidationLoader = DataLoader(ValidationSet,BATCH_SIZE)\n",
    "print(f'Trainset Length: {len(TrainSet)} Testset Length: {len(TestSet)} Validationset Length: {len(ValidationSet)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#definining the model\n",
    "#proposed function for stress level S = A/V where S is stress, A is arousal, and V is valence\n",
    "#since valence represents the positivity of the emotion, it would be inversely proportional to stress as higher valence means a better emotion\n",
    "#Since higher arousal can be generally translated to \n",
    "class StressScanner(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(StressScanner, self).__init__()\n",
    "        self.ConvolutionIn = torch.nn.Conv1d(in_channels=8, out_channels=16,kernel_size=3,padding=1)\n",
    "        self.ConvHidden1 = torch.nn.Conv1d(in_channels=16, out_channels=32,kernel_size=3,padding=1)\n",
    "        self.ConvHidden2 = torch.nn.Conv1d(in_channels=32, out_channels=64,kernel_size=3,padding=1)\n",
    "        self.linear1 = torch.nn.Linear(64, 41)\n",
    "        self.linear2 = torch.nn.Linear(41, 23)\n",
    "        self.linearOut = torch.nn.Linear(23, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.ConvolutionIn(x))\n",
    "        x = F.relu(self.ConvHidden1(x))\n",
    "        x = F.relu(self.ConvHidden2(x))\n",
    "        x = x.squeeze()\n",
    "        x = F.relu(self.linear1(x))\n",
    "        x = F.relu(self.linear2(x))\n",
    "        x = self.linearOut(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = StressScanner()\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "loss_fn = torch.nn.MSELoss().to(device)\n",
    "\n",
    "#We need to expirment with momemtum and learning rate to optimize training time and accuracy. \n",
    "#Accuracy should not be expect on the first run about, as the model is rellying on daq time and bvp to learn\n",
    "#daqtime will need to be removed as in the field it may introduce far to many inconsitencies\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001,momentum=0.1)\n",
    "CUDA_LAUNCH_BLOCKING=1\n",
    "TORCH_USE_CUDA_DSA=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train loop\n",
    "#Note: tb_writer is just a tensorboard writer for statistics\n",
    "def train(epoch, tb_writer):\n",
    "    current_loss = 0.0\n",
    "    last_loss = 0.0\n",
    "    for i, batch in enumerate(TrainLoader):\n",
    "        input,labels = batch\n",
    "        optimizer.zero_grad()\n",
    "        #The tensor is a size too small, so we squeeze and add an extra dimension \n",
    "        input = input.unsqueeze(2)\n",
    "        output = model(input)\n",
    "        \n",
    "        labels = labels.unsqueeze(1)\n",
    "\n",
    "        loss = loss_fn(output,labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        current_loss += loss.item() \n",
    "        if (i % 1000 == 0):\n",
    "            print(f'Epoch: {epoch} Loss: {current_loss}')\n",
    "            print(output.shape)\n",
    "            print(labels.shape)\n",
    "            last_loss = current_loss\n",
    "            current_loss = 0.0\n",
    "            running_loss = 0.0\n",
    "    return last_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp = datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "epoch_num = 0\n",
    "EPOCHS = 10\n",
    "\n",
    "best_loss = 1000000.0\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f'Epoch: {epoch}')\n",
    "    model.train(True)\n",
    "    train_loss = train(epoch_num,None)\n",
    "    running_loss = 0.0\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, validation_data in enumerate(ValidationLoader):\n",
    "            validation_inputs, validation_labels = validation_data\n",
    "            \n",
    "            validation_inputs = validation_inputs.unsqueeze(2)\n",
    "            validation_outputs = model(validation_inputs)\n",
    "            validation_labels = validation_labels.unsqueeze(1)\n",
    "\n",
    "            \n",
    "            validation_loss = loss_fn(validation_outputs, validation_labels)\n",
    "            running_loss += validation_loss\n",
    "    avg_validation_loss = running_loss / i+1\n",
    "    print(f'Train Loss: {train_loss} Validation Loss: {avg_validation_loss}')\n",
    "\n",
    "    \n",
    "    #track performance\n",
    "    if avg_validation_loss < best_loss:\n",
    "        best_loss = avg_validation_loss\n",
    "        model_path = f'./models/StressPredictor-{timestamp}.pth'\n",
    "        torch.save(model.state_dict(), model_path)\n",
    "    epoch_num += 1\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing\n",
    "worst = 0\n",
    "best = 99999\n",
    "model.eval()\n",
    "total_err = 0\n",
    "outs_to_plot = []\n",
    "labels_to_plot = []\n",
    "inputs_to_plot = []\n",
    "for i, batch in enumerate(TestLoader): \n",
    "    input, labels = batch\n",
    "    input = input.unsqueeze(2)\n",
    "    output = model(input)\n",
    "    outs_to_plot.append(output.squeeze().tolist())\n",
    "    labels_to_plot.append(labels.tolist())\n",
    "    inputs_to_plot.append(input.squeeze()[:,1].tolist())\n",
    "  \n",
    "    error = abs(torch.sum(output) - torch.sum(labels))\n",
    "    total_err = total_err + error\n",
    "\n",
    "    MAE = error/BATCH_SIZE\n",
    "    if MAE > worst:\n",
    "        worst = MAE\n",
    "    if MAE < best:\n",
    "        best = MAE\n",
    "    if(i % 1000 == 0):\n",
    "        print(f\"BEST: {best}\\nWORST: {worst} \\nTOTAL: {error/(len(TestLoader)*BATCH_SIZE)}\\n\")\n",
    "print(\"STATS FOR TEST:\\n\")\n",
    "print(f\"BEST: {best}\\nWORST: {worst} \\nTOTAL: {total_err/(len(TestLoader)*BATCH_SIZE)}\\n\")\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_flat = []\n",
    "y_pred_flat = []\n",
    "y_true_flat = []\n",
    "for subset in inputs_to_plot:\n",
    "  for item in subset:\n",
    "    x_flat.append(item)\n",
    "x = np.array(x_flat)\n",
    "\n",
    "for subset in outs_to_plot:\n",
    "  for item in subset:\n",
    "    y_pred_flat.append(item)\n",
    "y_pred = np.array(y_pred_flat)\n",
    "\n",
    "for subset in labels_to_plot:\n",
    "  for item in subset:\n",
    "    y_true_flat.append(item)\n",
    "y_true = np.array(y_true_flat)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure()\n",
    "plt.scatter(x,y_true)\n",
    "plt.scatter(x,y_pred)\n",
    "plt.legend(labels=[\"Predicted Values\",\"True Values\"])\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_to_plot"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pygameDL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
