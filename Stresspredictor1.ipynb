{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "from enum import Enum\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import math\n",
    "import pickle\n",
    "import datetime\n",
    "import os \n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
    "os.environ[\"TORCH_USE_CUDA_DSA\"] = \"1\"\n",
    "BATCH_SIZE = 224\n",
    "#TODO: build a validation/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "#Check if GPU is available and select if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "print(torch.cuda.is_available())\n",
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing user data\n",
    "\n",
    "subjects = []\n",
    "for i in range (1,31):\n",
    "    interimPysch = pd.read_csv('.\\\\CASE_full\\\\data\\\\non-interpolated\\\\physiological\\\\sub_' + str(i) + '.csv')\n",
    "    interimPysch = interimPysch.drop(columns=['video'])\n",
    "    interimPysch['daqtime'] = interimPysch['daqtime'].astype('int32')\n",
    "    interimAnote = pd.read_csv('.\\\\CASE_full\\\\data\\\\non-interpolated\\\\annotations\\\\sub_' + str(i) + '.csv')\n",
    "    interimAnote = interimAnote.drop(columns=['video'])\n",
    "    interimAnote['jstime'] = interimAnote['jstime'].astype('int32')\n",
    "    final = interimPysch.merge(interimAnote, left_on='daqtime',right_on='jstime', how='outer')\n",
    "    #jstime dropped as it is redundant\n",
    "    final = final.drop(columns=['jstime','daqtime'])\n",
    "    final = final.ffill()\n",
    "    final = final.bfill()\n",
    "    final.to_csv('.\\\\Processed-Data\\\\Filled-Data\\\\sub_' + str(i) + '_processed'+'.csv')\n",
    "    subjects.append(final)\n",
    "subjects[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def createStressLevel(Dataframe):\n",
    "    vals = []\n",
    "    valence = Dataframe.loc[:,'valence']\n",
    "    arousal = Dataframe.loc[:,'arousal']\n",
    "    for i in range(0,len(valence)):\n",
    "        vals.append(round((arousal[i]-0.5)*math.cos((math.pi/18)*(valence[i] - 0.5))))\n",
    "    return vals\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading datasets and converting them into tensors\n",
    "subjects = []\n",
    "global testSubjects\n",
    "global validationSubjects\n",
    "\n",
    "for i in range(1,31):\n",
    "   if i < 29:\n",
    "      temp = pd.read_csv('.\\\\Processed-Data\\\\Filled-Data\\\\sub_' + str(i) + '_processed'+'.csv')\n",
    "      temp['StressLevel'] = createStressLevel(temp)\n",
    "      subjects.append(temp)\n",
    "   elif i==29:\n",
    "      temp = pd.read_csv('.\\\\Processed-Data\\\\Filled-Data\\\\sub_' + str(i) + '_processed'+'.csv')\n",
    "      temp['StressLevel'] = createStressLevel(temp)\n",
    "      testSubjects = temp\n",
    "\n",
    "   else:\n",
    "      \n",
    "      temp = pd.read_csv('.\\\\Processed-Data\\\\Filled-Data\\\\sub_' + str(i) + '_processed'+'.csv')\n",
    "      temp['StressLevel'] = createStressLevel(temp)\n",
    "      validationSubjects = temp\n",
    "\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>ecg</th>\n",
       "      <th>bvp</th>\n",
       "      <th>gsr</th>\n",
       "      <th>rsp</th>\n",
       "      <th>skt</th>\n",
       "      <th>emg_zygo</th>\n",
       "      <th>emg_coru</th>\n",
       "      <th>emg_trap</th>\n",
       "      <th>valence</th>\n",
       "      <th>arousal</th>\n",
       "      <th>StressLevel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.856</td>\n",
       "      <td>36.545</td>\n",
       "      <td>24.949</td>\n",
       "      <td>27.649</td>\n",
       "      <td>31.675</td>\n",
       "      <td>8.438</td>\n",
       "      <td>7.781</td>\n",
       "      <td>-52.548</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.869</td>\n",
       "      <td>36.671</td>\n",
       "      <td>24.953</td>\n",
       "      <td>27.668</td>\n",
       "      <td>31.689</td>\n",
       "      <td>8.602</td>\n",
       "      <td>7.863</td>\n",
       "      <td>-52.466</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.859</td>\n",
       "      <td>36.661</td>\n",
       "      <td>24.945</td>\n",
       "      <td>27.649</td>\n",
       "      <td>31.679</td>\n",
       "      <td>8.561</td>\n",
       "      <td>7.781</td>\n",
       "      <td>-52.507</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.866</td>\n",
       "      <td>36.410</td>\n",
       "      <td>24.945</td>\n",
       "      <td>27.668</td>\n",
       "      <td>31.682</td>\n",
       "      <td>8.684</td>\n",
       "      <td>7.945</td>\n",
       "      <td>-52.548</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.866</td>\n",
       "      <td>36.526</td>\n",
       "      <td>24.953</td>\n",
       "      <td>27.649</td>\n",
       "      <td>31.686</td>\n",
       "      <td>8.644</td>\n",
       "      <td>7.904</td>\n",
       "      <td>-52.466</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2358253</th>\n",
       "      <td>2451578.0</td>\n",
       "      <td>1.750</td>\n",
       "      <td>35.799</td>\n",
       "      <td>24.432</td>\n",
       "      <td>27.049</td>\n",
       "      <td>28.233</td>\n",
       "      <td>7.534</td>\n",
       "      <td>7.575</td>\n",
       "      <td>-80.228</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2358254</th>\n",
       "      <td>2451579.0</td>\n",
       "      <td>1.799</td>\n",
       "      <td>35.896</td>\n",
       "      <td>24.452</td>\n",
       "      <td>27.058</td>\n",
       "      <td>28.236</td>\n",
       "      <td>7.617</td>\n",
       "      <td>7.575</td>\n",
       "      <td>-80.433</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2358255</th>\n",
       "      <td>2451580.0</td>\n",
       "      <td>1.815</td>\n",
       "      <td>35.974</td>\n",
       "      <td>24.417</td>\n",
       "      <td>27.068</td>\n",
       "      <td>28.240</td>\n",
       "      <td>7.534</td>\n",
       "      <td>7.575</td>\n",
       "      <td>-80.515</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2358256</th>\n",
       "      <td>2451581.0</td>\n",
       "      <td>1.828</td>\n",
       "      <td>35.828</td>\n",
       "      <td>24.421</td>\n",
       "      <td>27.049</td>\n",
       "      <td>28.229</td>\n",
       "      <td>7.534</td>\n",
       "      <td>7.452</td>\n",
       "      <td>-80.556</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2358257</th>\n",
       "      <td>2451582.0</td>\n",
       "      <td>1.809</td>\n",
       "      <td>35.954</td>\n",
       "      <td>24.421</td>\n",
       "      <td>27.029</td>\n",
       "      <td>28.229</td>\n",
       "      <td>7.575</td>\n",
       "      <td>7.452</td>\n",
       "      <td>-80.269</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2358258 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Unnamed: 0    ecg     bvp     gsr     rsp     skt  emg_zygo  \\\n",
       "0               0.0  0.856  36.545  24.949  27.649  31.675     8.438   \n",
       "1               1.0  0.869  36.671  24.953  27.668  31.689     8.602   \n",
       "2               2.0  0.859  36.661  24.945  27.649  31.679     8.561   \n",
       "3               3.0  0.866  36.410  24.945  27.668  31.682     8.684   \n",
       "4               4.0  0.866  36.526  24.953  27.649  31.686     8.644   \n",
       "...             ...    ...     ...     ...     ...     ...       ...   \n",
       "2358253   2451578.0  1.750  35.799  24.432  27.049  28.233     7.534   \n",
       "2358254   2451579.0  1.799  35.896  24.452  27.058  28.236     7.617   \n",
       "2358255   2451580.0  1.815  35.974  24.417  27.068  28.240     7.534   \n",
       "2358256   2451581.0  1.828  35.828  24.421  27.049  28.229     7.534   \n",
       "2358257   2451582.0  1.809  35.954  24.421  27.029  28.229     7.575   \n",
       "\n",
       "         emg_coru  emg_trap  valence  arousal  StressLevel  \n",
       "0           7.781   -52.548      5.0      5.0            3  \n",
       "1           7.863   -52.466      5.0      5.0            3  \n",
       "2           7.781   -52.507      5.0      5.0            3  \n",
       "3           7.945   -52.548      5.0      5.0            3  \n",
       "4           7.904   -52.466      5.0      5.0            3  \n",
       "...           ...       ...      ...      ...          ...  \n",
       "2358253     7.575   -80.228      5.0      5.0            3  \n",
       "2358254     7.575   -80.433      5.0      5.0            3  \n",
       "2358255     7.575   -80.515      5.0      5.0            3  \n",
       "2358256     7.452   -80.556      5.0      5.0            3  \n",
       "2358257     7.452   -80.269      5.0      5.0            3  \n",
       "\n",
       "[2358258 rows x 12 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "subjects[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combining Dataset and train set frames\n",
    "#it may be required that timestamps be dropped from the prediciton model entirely, or atleast switched to date time, as the model\n",
    "#may try to learn emotions based on when measuring starts and finishes. This could be problematic\n",
    "#as sessions in the field could go longer than eny training sessions, or disconnects could restart sessions\n",
    "datasetFrame = pd.concat(subjects.copy())\n",
    "datasetFrame = datasetFrame.drop(columns=['Unnamed: 0'])\n",
    "trainLabels = torch.Tensor(datasetFrame['StressLevel'].values.astype(int))\n",
    "datasetFrame = datasetFrame.drop(columns=['StressLevel','valence','arousal'])\n",
    "\n",
    "testFrame = testSubjects.copy()\n",
    "testFrame = testFrame.drop(columns=['Unnamed: 0']) \n",
    "testLabels = torch.Tensor(testFrame['StressLevel'].values.astype(int)) \n",
    "testFrame = testFrame.drop(columns=['StressLevel','valence','arousal'])\n",
    "\n",
    "validationFrame = validationSubjects.copy()\n",
    "validationFrame = validationFrame.drop(columns=['Unnamed: 0'])\n",
    "validationLabels = torch.Tensor(validationFrame['StressLevel'].values.astype(int))\n",
    "validationFrame = validationFrame.drop(columns=['StressLevel','valence','arousal'])\n",
    "\n",
    "datasetFrame.to_csv('.\\\\Processed-Data\\\\trainingData.csv',index=False)\n",
    "testFrame.to_csv('.\\\\Processed-Data\\\\testData.csv',index=False)\n",
    "validationFrame.to_csv('.\\\\Processed-Data\\\\validationData.csv',index=False)\n",
    "pickle.dump(trainLabels, open('.\\\\Processed-Data\\\\trainLabels.pkl','wb'))\n",
    "pickle.dump(testLabels, open('.\\\\Processed-Data\\\\testLabels.pkl','wb'))\n",
    "pickle.dump(validationLabels, open('.\\\\Processed-Data\\\\validationLabels.pkl','wb'))\n",
    "\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainLabels = pickle.load(open('.\\\\Processed-Data\\\\trainLabels.pkl','rb')).to(device)\n",
    "testLabels = pickle.load(open('.\\\\Processed-Data\\\\testLabels.pkl','rb')).to(device)\n",
    "validationLabels = pickle.load(open('.\\\\Processed-Data\\\\validationLabels.pkl','rb')).to(device)\n",
    "datasetFrame = pd.read_csv('.\\\\Processed-Data\\\\trainingData.csv')\n",
    "testFrame = pd.read_csv('.\\\\Processed-Data\\\\testData.csv')\n",
    "validationFrame = pd.read_csv('.\\\\Processed-Data\\\\validationData.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainTensor = torch.tensor(datasetFrame.values.astype(float),dtype=torch.float32).to(device)\n",
    "testTensor = torch.tensor(testFrame.values.astype(float), dtype=torch.float32).to(device)\n",
    "validationTensor = torch.tensor(validationFrame.values.astype(float), dtype=torch.float32).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainTensor shape: torch.Size([68511001, 8]) testTensor shape: torch.Size([2451501, 8]) validationTensor shape: torch.Size([2451501, 8])\n",
      "Train type: torch.float32 Test type: torch.float32 Validation type: torch.float32\n"
     ]
    }
   ],
   "source": [
    "print(f'trainTensor shape: {trainTensor.shape} testTensor shape: {testTensor.shape} validationTensor shape: {validationTensor.shape}' )\n",
    "print(f'Train type: {trainTensor.dtype} Test type: {testTensor.dtype} Validation type: {validationTensor.dtype}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainset Length: 68511001 Testset Length: 2451501 Validationset Length: 2451501\n"
     ]
    }
   ],
   "source": [
    "TrainSet = TensorDataset(trainTensor,trainLabels)\n",
    "ValidationSet = TensorDataset(validationTensor,validationLabels)\n",
    "TestSet = TensorDataset(testTensor,testLabels)\n",
    "TrainLoader = DataLoader(TrainSet,BATCH_SIZE,shuffle=False)\n",
    "TestLoader = DataLoader(TestSet,BATCH_SIZE)\n",
    "ValidationLoader = DataLoader(ValidationSet,BATCH_SIZE)\n",
    "print(f'Trainset Length: {len(TrainSet)} Testset Length: {len(TestSet)} Validationset Length: {len(ValidationSet)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#definining the model\n",
    "#proposed function for stress level S = A/V where S is stress, A is arousal, and V is valence\n",
    "#since valence represents the positivity of the emotion, it would be inversely proportional to stress as higher valence means a better emotion\n",
    "#Since higher arousal can be generally translated to \n",
    "class StressScanner(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(StressScanner, self).__init__()\n",
    "        self.ConvolutionIn = torch.nn.Conv1d(in_channels=8, out_channels=16,kernel_size=3,padding=1)\n",
    "        self.ConvHidden1 = torch.nn.Conv1d(in_channels=16, out_channels=32,kernel_size=3,padding=1)\n",
    "        self.ConvHidden2 = torch.nn.Conv1d(in_channels=32, out_channels=64,kernel_size=3,padding=1)\n",
    "        self.linear1 = torch.nn.Linear(64, 41)\n",
    "        self.linear2 = torch.nn.Linear(41, 23)\n",
    "        self.linearOut = torch.nn.Linear(23, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.ConvolutionIn(x))\n",
    "        x = F.relu(self.ConvHidden1(x))\n",
    "        x = F.relu(self.ConvHidden2(x))\n",
    "        x = x.squeeze()\n",
    "        x = F.relu(self.linear1(x))\n",
    "        x = F.relu(self.linear2(x))\n",
    "        x = self.linearOut(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = StressScanner()\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "#We need to expirment with momemtum and learning rate to optimize training time and accuracy. \n",
    "#Accuracy should not be expect on the first run about, as the model is rellying on daq time and bvp to learn\n",
    "#daqtime will need to be removed as in the field it may introduce far to many inconsitencies\n",
    "\n",
    "optimizer = torch.optim.ASGD(model.parameters(), lr=0.001)\n",
    "CUDA_LAUNCH_BLOCKING=1\n",
    "TORCH_USE_CUDA_DSA=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train loop\n",
    "#Note: tb_writer is just a tensorboard writer for statistics\n",
    "def train(epoch, tb_writer):\n",
    "    current_loss = 0.0\n",
    "    last_loss = 0.0\n",
    "    for i, batch in enumerate(TrainLoader):\n",
    "        input,labels = batch\n",
    "        optimizer.zero_grad()\n",
    "        #The tensor is a size too small, so we squeeze and add an extra dimension \n",
    "        input = input.unsqueeze(2)\n",
    "        output = model(input)\n",
    "\n",
    "        output = output.unsqueeze(2)\n",
    "        labels = labels.long()\n",
    "        labels = labels.unsqueeze(1)\n",
    "\n",
    "\n",
    "\n",
    "        loss = loss_fn(output,labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        current_loss += loss.item() \n",
    "        if (i % 1000 == 0):\n",
    "            print(f'Epoch: {epoch} Loss: {current_loss}')\n",
    "            print(output.shape)\n",
    "            print(labels.shape)\n",
    "            last_loss = current_loss\n",
    "            current_loss = 0.0\n",
    "            #tb_x = epoch * len(TrainLoader) + i + 1\n",
    "            #tb_writer.add_scalar('Loss/train', loss.item(), tb_x)\n",
    "            running_loss = 0.0\n",
    "    return last_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp = datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "epoch_num = 0\n",
    "EPOCHS = 10\n",
    "\n",
    "best_loss = 1000000.0\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f'Epoch: {epoch}')\n",
    "    model.train(True)\n",
    "    train_loss = train(epoch_num,None)\n",
    "    running_loss = 0.0\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, validation_data in enumerate(ValidationLoader):\n",
    "            validation_inputs, validation_labels = validation_data\n",
    "            \n",
    "            validation_inputs = validation_inputs.unsqueeze(2)\n",
    "            validation_outputs = model(validation_inputs)\n",
    "            validation_outputs = validation_outputs.unsqueeze(2)\n",
    "\n",
    "            validation_labels = validation_labels.long()\n",
    "            validation_labels = validation_labels.unsqueeze(1)\n",
    "\n",
    "            \n",
    "            validation_loss = loss_fn(validation_outputs, validation_labels)\n",
    "            running_loss += validation_loss\n",
    "    avg_validation_loss = running_loss / i+1\n",
    "    print(f'Train Loss: {train_loss} Validation Loss: {avg_validation_loss}')\n",
    "\n",
    "    \n",
    "    #track performance\n",
    "    if avg_validation_loss < best_loss:\n",
    "        best_loss = avg_validation_loss\n",
    "        model_path = f'./models/StressPredictor-{timestamp}.pth'\n",
    "        torch.save(model.state_dict(), model_path)\n",
    "    epoch_num += 1\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StressScanner(\n",
      "  (ConvolutionIn): Conv1d(8, 16, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "  (ConvHidden1): Conv1d(16, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "  (ConvHidden2): Conv1d(32, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "  (linear1): Linear(in_features=64, out_features=41, bias=True)\n",
      "  (linear2): Linear(in_features=41, out_features=23, bias=True)\n",
      "  (linearOut): Linear(in_features=23, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Saving model once training is complete\n",
    "saved_model = StressScanner()\n",
    "saved_model.load_state_dict(torch.load(\".\\models\\StressPredictor-2023-08-13_11-01-12.pth\"))\n",
    "model = saved_model\n",
    "model = model.to(device)\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing\n",
    "def test():\n",
    "  with torch.no_grad():    \n",
    "    total_loss = 0\n",
    "    for i,batch in enumerate(TestLoader):\n",
    "      input, label = batch\n",
    "      input = input.unsqueeze(2)\n",
    "      output = model(input)\n",
    "      output = output.unsqueeze(2)\n",
    "      label = label.long()\n",
    "      label = label.unsqueeze(1)\n",
    "      loss = loss_fn(output, label)\n",
    "      total_loss += loss\n",
    "    print(f\"Test Loss: {total_loss/len(TestLoader)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.9593360424041748\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Stress_Predictor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
